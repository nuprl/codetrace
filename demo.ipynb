{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax-dependent trace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchetti.f/.local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 34079899648 used for device 0, reserved 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "CACHE_DIR = \"/scratch/lucchetti.f/models/\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = CACHE_DIR\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "from model_utils import *\n",
    "import tqdm as notebook_tqdm\n",
    "from model import ModelLoader\n",
    "\n",
    "# from model_loader import ModelLoader\n",
    "# from model_manager import ModelManager\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "#MODEL_NAME = \"Salesforce/codegen-16B-mono\"\n",
    "MODEL_NAME = \"bigcode/santacoder\"\n",
    "\n",
    "check_devs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = ModelLoader(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357992960 / 34079899648 used for device 0, reserved 2373976064\n"
     ]
    }
   ],
   "source": [
    "check_devs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'int x = 0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lm.model\n",
    "tokenizer = lm.tokenizer\n",
    "\n",
    "prompts = [\"\"\"# intialize three integers\n",
    "           int x = 1\n",
    "           int y = 2\n",
    "           int z =\"\"\"]\n",
    "\n",
    "prompts = [\"\"\"int x =\"\"\"]\n",
    "\n",
    "# vanilla generate:\n",
    "\n",
    "tokenized = tokenizer(prompts, return_tensors=\"pt\")\n",
    "outputs = model.generate(tokenized.input_ids.to(model.device), max_new_tokens=2, top_k = 1)\n",
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace + activation patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchetti.f/codetrace/model.py:134: UserWarning: The model `bigcode/santacoder` of type `gpt2` already implements or can't utilize `use_cache` for fast generation. Setting `use_cache = False`.\n",
      "  warnings.warn(f\"The model `{type(self.model)}` can't utilize `use_cache` for fast generation. Setting `use_cache = False`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt <0> ==> [(' ', 0.6357), (' (', 0.0573), (' x', 0.0188), (' -', 0.0176), (' i', 0.0134)]\n",
      "prompt <0> ==> [('0', 0.8682), ('1', 0.082), ('2', 0.0167), ('3', 0.0099), ('5', 0.0082)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_tokenized': [[('int', 389), (' x', 727), (' =', 256)]],\n",
       " 'generated_tokens': [[[{'token': ' ', 'id': 207, 'p': 0.6357421875},\n",
       "    {'token': ' (', 'id': 305, 'p': 0.05731201171875},\n",
       "    {'token': ' x', 'id': 727, 'p': 0.0187530517578125},\n",
       "    {'token': ' -', 'id': 459, 'p': 0.017608642578125},\n",
       "    {'token': ' i', 'id': 583, 'p': 0.013397216796875}],\n",
       "   [{'token': '0', 'id': 15, 'p': 0.8681640625},\n",
       "    {'token': '1', 'id': 16, 'p': 0.08203125},\n",
       "    {'token': '2', 'id': 17, 'p': 0.01666259765625},\n",
       "    {'token': '3', 'id': 18, 'p': 0.00994873046875},\n",
       "    {'token': '5', 'id': 20, 'p': 0.00824737548828125}]]],\n",
       " 'activations': {'transformer.h.5': array([[[ 0.8833 , -0.8457 ,  0.2708 , ..., -0.595  , -0.51   ,\n",
       "            0.502  ],\n",
       "          [-0.2861 ,  0.1284 , -0.0094 , ...,  0.191  , -0.9004 ,\n",
       "            0.496  ],\n",
       "          [ 0.376  , -0.4688 ,  0.1257 , ...,  0.0729 ,  0.279  ,\n",
       "            0.4692 ],\n",
       "          [-0.1093 , -0.8286 ,  0.626  , ..., -0.05634,  0.3862 ,\n",
       "           -0.09033]]], dtype=float16),\n",
       "  'transformer.h.6': array([[[ 0.8555 , -0.8726 ,  0.3145 , ..., -0.5713 , -0.5    ,\n",
       "            0.4854 ],\n",
       "          [-0.1964 ,  0.09265,  0.2441 , ...,  0.3215 , -0.9863 ,\n",
       "            0.41   ],\n",
       "          [ 0.601  , -0.743  ,  0.1312 , ...,  0.1909 ,  0.06604,\n",
       "            0.718  ],\n",
       "          [ 0.1815 , -0.932  ,  0.5513 , ..., -0.2332 ,  0.4233 ,\n",
       "            0.09656]]], dtype=float16),\n",
       "  'transformer.h.7': array([[[ 0.8486 , -0.8013 ,  0.3767 , ..., -0.5176 , -0.4253 ,\n",
       "            0.4888 ],\n",
       "          [-0.1459 , -0.06238, -0.1389 , ...,  0.2983 , -1.156  ,\n",
       "            0.3943 ],\n",
       "          [ 0.583  , -0.9287 , -0.1383 , ...,  0.2    ,  0.0873 ,\n",
       "            0.699  ],\n",
       "          [ 0.1997 , -0.8867 ,  0.5547 , ..., -0.2583 ,  0.455  ,\n",
       "            0.03662]]], dtype=float16),\n",
       "  'transformer.h.8': array([[[ 0.829  , -0.7563 ,  0.3545 , ..., -0.535  , -0.4016 ,\n",
       "            0.4744 ],\n",
       "          [-0.1832 ,  0.1001 ,  0.01819, ...,  0.4197 , -1.576  ,\n",
       "            0.186  ],\n",
       "          [ 0.557  , -1.14   , -0.2499 , ...,  0.253  ,  0.06995,\n",
       "            0.595  ],\n",
       "          [ 0.4233 , -0.921  ,  0.458  , ..., -0.3806 ,  0.394  ,\n",
       "            0.0101 ]]], dtype=float16),\n",
       "  'transformer.h.9': array([[[ 0.77   , -0.6924 ,  0.3533 , ..., -0.539  , -0.3877 ,\n",
       "            0.4253 ],\n",
       "          [-0.1469 ,  0.1868 ,  0.0713 , ...,  0.2625 , -1.407  ,\n",
       "            0.1449 ],\n",
       "          [ 0.5723 , -0.972  , -0.08484, ...,  0.186  ,  0.2179 ,\n",
       "            0.7056 ],\n",
       "          [ 0.3162 , -0.7876 ,  0.5576 , ..., -0.4182 ,  0.3652 ,\n",
       "            0.1531 ]]], dtype=float16)}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt, ret_dict = lm.generate(\n",
    "    prompts,\n",
    "    max_out_len=5,\n",
    "    argmax_greedy= True,\n",
    "    debug = True,\n",
    "    request_activations= [lm.layer_name_format.format(i) for i in range(5,10)]\n",
    ")\n",
    "ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
