{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookuptable experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franlucc/mechinterp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 84978434048 used for device 0, reserved 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/franlucc/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## discovery cluster setup\n",
    "# CACHE_DIR = \"/scratch/lucchetti.f/models/\"\n",
    "# os.environ['TRANSFORMERS_CACHE'] = CACHE_DIR\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import random\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from model_utils import *\n",
    "import tqdm as notebook_tqdm\n",
    "from trace_model import ModelLoader\n",
    "from pandas import DataFrame\n",
    "torch.set_grad_enabled(False)\n",
    "from tqdm import tqdm \n",
    "from model_utils import layername\n",
    "import numpy as np\n",
    "from extract_data import *\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from random import sample\n",
    "from patch import *\n",
    "\n",
    "import re\n",
    "check_devs()\n",
    "# clear_devs()\n",
    "torch.cuda.is_available()\n",
    "\n",
    "MODEL_NAME = \"/home/arjun/models/starcoderbase-1b/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4615938048 / 84978434048 used for device 0, reserved 4617928704\n"
     ]
    }
   ],
   "source": [
    "lm = ModelLoader(MODEL_NAME)\n",
    "check_devs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## synthetic look-up table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"\"\"def func(i : int) -> str:\n",
    "    if i == 0:\n",
    "        return \"cat\"\n",
    "    elif i == 1:\n",
    "        return \"speed\"\n",
    "    elif i == 3:\n",
    "        return \"city\"\n",
    "    else:\n",
    "        return \"number\"\n",
    "\"\"\"\n",
    "\n",
    "def make_assert(n):\n",
    "    return f\"assert func({n}) == \\\"\"\n",
    "\n",
    "assertions = [\n",
    "    \"assert func(0) == \\\"\",\n",
    "    \"assert func(1) == \\\"\",\n",
    "    \"assert func(2) == \\\"\",\n",
    "    \"assert func(3) == \\\"\",\n",
    "    \"assert func(999) == \\\"\",\n",
    "    \n",
    "]\n",
    "\n",
    "def layernum(lname):\n",
    "    return int(lname.split(\".\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: prune transformer, get earliest layer that successfully completes task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem: sampling is fast, greedy is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt, ret_dict = lm.trace_generate(prompt + \"\\n\" + make_assert(99),\n",
    "                                  max_new_toks=1,\n",
    "                                  request_logits=[layername(lm.model, l) for l in range(10,30)],\n",
    "                                  sample_from_topk_logits=None)\n",
    "out = txt.replace(prompt + \"\\n\" + make_assert(99), \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)\n",
    "ret_dict[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_lookuptable(max_n, prompt, sample_from=None):\n",
    "    res = []\n",
    "    exec(prompt)\n",
    "    for n in range(0, max_n):\n",
    "        # for k in range(0, 20):\n",
    "            txt, ret_dict = lm.trace_generate(prompt + \"\\n\" + make_assert(n),\n",
    "                                            max_new_toks=1,\n",
    "                                            request_logits=[layername(lm.model, l) for l in range(10,30)],\n",
    "                                            sample_from_topk_logits=sample_from)\n",
    "            out = txt.replace(prompt + \"\\n\" + make_assert(n), \"\")\n",
    "            for lname, logits in ret_dict[\"logits\"].items():\n",
    "                if out in [str(x) for (x,_) in logits]:\n",
    "                    gold = eval(f\"func({n})\")\n",
    "                    res.append(((out == gold), out, gold, n, layernum(lname)))\n",
    "                    break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to break lookup table task\n",
    "\n",
    "make harder by increasing lenght. At what point is transformer unsure what task this is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(res, name, header=['prompt_seed','is_correct','completion', 'gold', 'input n', 'layernum']):\n",
    "    ds = DataFrame.from_dict(res)\n",
    "    ds.to_csv(f\"../results/{name}.csv\", header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lookup_table(n, seed=0):\n",
    "    assert n < 25, \"n must be less than 25\"\n",
    "    random.seed(seed)\n",
    "    nums = sample(list(range(n)), n)\n",
    "    words = sample(list(range(n+1)), n+1)\n",
    "    s = f\"def func(i : int) -> str:\\n\\tif i == {nums[0]}:\\n\\t\\treturn \\\"{chr(97+words[0])}\\\"\\n\"\n",
    "    for i,k in enumerate(nums[1:]):\n",
    "        s += f\"\\telif i == {k}:\\n\\t\\treturn \\\"{chr(97+words[i+1])}\\\"\\n\"\n",
    "    s += f\"\\telse:\\n\\t\\treturn \\\"{chr(97+words[-1])}\\\"\"\n",
    "    return s.replace(\"\\t\",\"    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_false_task(max_n, prompt, seed, len_table=12):\n",
    "    res = []\n",
    "    exec(prompt)\n",
    "    \n",
    "    for n in range(0, max_n):\n",
    "        # for k in range(0, 20):\n",
    "            txt, ret_dict = lm.trace_generate(prompt + \"\\n\" + make_assert(n),\n",
    "                                            max_new_toks=1,\n",
    "                                            request_logits=[layername(lm.model, l) for l in range(10,20)],\n",
    "                                            do_greedy_decoding=True)\n",
    "            out = txt.replace(prompt + \"\\n\" + make_assert(n), \"\")\n",
    "            for lname, logits in ret_dict[\"logits\"].items():\n",
    "                if out in [str(x) for (x,_) in logits]:\n",
    "                    gold = eval(f\"func({n})\")\n",
    "                    def first_or_last_match(out, i):\n",
    "                        exec(prompt)\n",
    "                        first_digit = eval(f\"func({str(i)[0]})\")\n",
    "                        last_digit = eval(f\"func({str(i)[-1]})\")\n",
    "                        if first_digit == out:\n",
    "                            return \"Match_First_Digit_False_Task\"\n",
    "                        elif last_digit == out:\n",
    "                            return \"Match_Last_Digit_False_Task\"\n",
    "                        else:\n",
    "                            return \"Neither_False_Task\"\n",
    "                    is_correct = (out == gold)\n",
    "                    first_or_last_match_str = first_or_last_match(out, n) if not is_correct else \"NA\"\n",
    "                    res.append((len_table, seed, is_correct, first_or_last_match_str, out, gold, n, layernum(lname)))\n",
    "                    break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def exp_false_task(seed_range, lengths_table=[3,6,9,12], seed_start=0):\n",
    "    fp = open(f\"../results/log.json\", \"w\")\n",
    "    tot_res = []\n",
    "    for len_table in tqdm(lengths_table):\n",
    "        for seed in range(seed_start, seed_range):\n",
    "            prompt = make_lookup_table(len_table, seed=seed)\n",
    "            res = trace_false_task(50, prompt, seed, len_table=len_table)\n",
    "            json.dump(res, fp)\n",
    "            tot_res += res\n",
    "    fp.close()\n",
    "    return tot_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [16:27<00:00, 246.77s/it]\n"
     ]
    }
   ],
   "source": [
    "tot_res = exp_false_task(2)\n",
    "save_to_csv(tot_res, \"1ftb_full_lookuptable_task0\", header =[\"table_len\",\"seed\",\"is_correct\",\"first_or_last_match\",\"out\",\"gold\",\"func(n)\",\"earliest_layer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [20:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 tot_res = exp_false_task(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span>, seed_start=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>save_to_csv(tot_res, <span style=\"color: #808000; text-decoration-color: #808000\">\"1b_full_lookuptable_task1\"</span>, header =[<span style=\"color: #808000; text-decoration-color: #808000\">\"table_len\"</span>,<span style=\"color: #808000; text-decoration-color: #808000\">\"seed\"</span>,<span style=\"color: #808000; text-decoration-color: #808000\">\"is_correc</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">exp_false_task</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> len_table <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> tqdm(lengths_table):                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> seed <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(seed_start, seed_range):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>prompt = make_lookup_table(len_table, seed=seed)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 8 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>res = trace_false_task(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">50</span>, prompt, seed, len_table=len_table)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>json.dump(res, fp)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>tot_res += res                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>fp.close()                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trace_false_task</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> n <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, max_n):                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># for k in range(0, 20):</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 7 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>txt, ret_dict = lm.trace_generate(prompt + <span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\"</span> + make_assert(n),               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   </span>max_new_toks=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>,                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   </span>request_logits=[layername(lm.model, l) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> l    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   </span>do_greedy_decoding=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/franlucc/codetrace/notebooks/../</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trace_model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">215</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trace_generate</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># collect tokens generated from final layer</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(input_ids.size(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)):                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>215 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>generated_tokens[i].append(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>[                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">217 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>{<span style=\"color: #808000; text-decoration-color: #808000\">\"token\"</span>: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.tokenizer.decode(t), <span style=\"color: #808000; text-decoration-color: #808000\">\"id\"</span>: t.item(), <span style=\"color: #808000; text-decoration-color: #808000\">\"p\"</span>: sof   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> t <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> topk_logits[i]                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/franlucc/codetrace/notebooks/../</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trace_model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">216</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># collect tokens generated from final layer</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(input_ids.size(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)):                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>generated_tokens[i].append(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>216 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>[                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">217 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>{<span style=\"color: #808000; text-decoration-color: #808000\">\"token\"</span>: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.tokenizer.decode(t), <span style=\"color: #808000; text-decoration-color: #808000\">\"id\"</span>: t.item(), <span style=\"color: #808000; text-decoration-color: #808000\">\"p\"</span>: sof   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> t <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> topk_logits[i]                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>]                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/franlucc/mechinterp/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">484</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decode</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3481 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">`str`: The decoded sentence.</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3482 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3483 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Convert inputs to python lists</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3484 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>token_ids = to_py_obj(token_ids)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3485 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._decode(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3487 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>token_ids=token_ids,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/franlucc/mechinterp/lib/python3.10/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">generic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">193</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to_py_obj</span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> is_tf_tensor(obj):                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> obj.numpy().tolist()                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> is_torch_tensor(obj):                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>193 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> obj.detach().cpu().tolist()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">194 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> is_jax_tensor(obj):                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> np.asarray(obj).tolist()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(obj, (np.ndarray, np.number)):  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># tolist also works on 0d np arrays</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 tot_res = exp_false_task(\u001b[94m20\u001b[0m, seed_start=\u001b[94m2\u001b[0m)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0msave_to_csv(tot_res, \u001b[33m\"\u001b[0m\u001b[33m1b_full_lookuptable_task1\u001b[0m\u001b[33m\"\u001b[0m, header =[\u001b[33m\"\u001b[0m\u001b[33mtable_len\u001b[0m\u001b[33m\"\u001b[0m,\u001b[33m\"\u001b[0m\u001b[33mseed\u001b[0m\u001b[33m\"\u001b[0m,\u001b[33m\"\u001b[0m\u001b[33mis_correc\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mexp_false_task\u001b[0m:\u001b[94m8\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m len_table \u001b[95min\u001b[0m tqdm(lengths_table):                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m seed \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(seed_start, seed_range):                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   │   │   \u001b[0mprompt = make_lookup_table(len_table, seed=seed)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 8 \u001b[2m│   │   │   \u001b[0mres = trace_false_task(\u001b[94m50\u001b[0m, prompt, seed, len_table=len_table)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   │   │   \u001b[0mjson.dump(res, fp)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   │   \u001b[0mtot_res += res                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   \u001b[0mfp.close()                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrace_false_task\u001b[0m:\u001b[94m7\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m n \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[94m0\u001b[0m, max_n):                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# for k in range(0, 20):\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 7 \u001b[2m│   │   │   \u001b[0mtxt, ret_dict = lm.trace_generate(prompt + \u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\"\u001b[0m + make_assert(n),               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   \u001b[0mmax_new_toks=\u001b[94m1\u001b[0m,                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   \u001b[0mrequest_logits=[layername(lm.model, l) \u001b[94mfor\u001b[0m l    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   \u001b[0mdo_greedy_decoding=\u001b[94mTrue\u001b[0m)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/franlucc/codetrace/notebooks/../\u001b[0m\u001b[1;33mtrace_model.py\u001b[0m:\u001b[94m215\u001b[0m in \u001b[92mtrace_generate\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m212 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m213 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# collect tokens generated from final layer\u001b[0m                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(input_ids.size(\u001b[94m0\u001b[0m)):                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m215 \u001b[2m│   │   │   │   │   \u001b[0mgenerated_tokens[i].append(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m[                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m217 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m{\u001b[33m\"\u001b[0m\u001b[33mtoken\u001b[0m\u001b[33m\"\u001b[0m: \u001b[96mself\u001b[0m.tokenizer.decode(t), \u001b[33m\"\u001b[0m\u001b[33mid\u001b[0m\u001b[33m\"\u001b[0m: t.item(), \u001b[33m\"\u001b[0m\u001b[33mp\u001b[0m\u001b[33m\"\u001b[0m: sof   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m t \u001b[95min\u001b[0m topk_logits[i]                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/franlucc/codetrace/notebooks/../\u001b[0m\u001b[1;33mtrace_model.py\u001b[0m:\u001b[94m216\u001b[0m in \u001b[92m<listcomp>\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m213 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# collect tokens generated from final layer\u001b[0m                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(input_ids.size(\u001b[94m0\u001b[0m)):                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mgenerated_tokens[i].append(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m216 \u001b[2m│   │   │   │   │   │   \u001b[0m[                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m217 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m{\u001b[33m\"\u001b[0m\u001b[33mtoken\u001b[0m\u001b[33m\"\u001b[0m: \u001b[96mself\u001b[0m.tokenizer.decode(t), \u001b[33m\"\u001b[0m\u001b[33mid\u001b[0m\u001b[33m\"\u001b[0m: t.item(), \u001b[33m\"\u001b[0m\u001b[33mp\u001b[0m\u001b[33m\"\u001b[0m: sof   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m t \u001b[95min\u001b[0m topk_logits[i]                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m]                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/franlucc/mechinterp/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_utils_base.py\u001b[0m:\u001b[94m3\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m484\u001b[0m in \u001b[92mdecode\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3481 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33m`str`: The decoded sentence.\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3482 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3483 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Convert inputs to python lists\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3484 \u001b[2m│   │   \u001b[0mtoken_ids = to_py_obj(token_ids)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3485 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3486 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._decode(                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3487 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_ids=token_ids,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/franlucc/mechinterp/lib/python3.10/site-packages/transformers/utils/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m193\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mto_py_obj\u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m190 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m is_tf_tensor(obj):                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m obj.numpy().tolist()                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m is_torch_tensor(obj):                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m193 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m obj.detach().cpu().tolist()                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m is_jax_tensor(obj):                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m np.asarray(obj).tolist()                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(obj, (np.ndarray, np.number)):  \u001b[2m# tolist also works on 0d np arrays\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tot_res = exp_false_task(20, seed_start=2)\n",
    "save_to_csv(tot_res, \"1b_full_lookuptable_task1\", header =[\"table_len\",\"seed\",\"is_correct\",\"first_or_last_match\",\"out\",\"gold\",\"func(n)\",\"earliest_layer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_res = exp_false_task(20)\n",
    "save_to_csv(tot_res, \"1b_lookup_table_false_task_small0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the attn heads responsible\n",
    "\n",
    "layer 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads_to_noise = [(h, 18) for h in range(48)]\n",
    "## noise create\n",
    "uniform_noise = False\n",
    "noise = 0.1\n",
    "replace=True\n",
    "rs = numpy.random.RandomState(1)  # For reproducibility, use pseudorandom noise\n",
    "if uniform_noise:\n",
    "    prng = lambda *shape: rs.uniform(-1, 1, shape)\n",
    "else:\n",
    "    prng = lambda *shape: rs.randn(*shape)\n",
    "if isinstance(noise, float):\n",
    "    noise_fn = lambda x: noise * x\n",
    "else:\n",
    "    noise_fn = noise\n",
    "    \n",
    "heads_to_noise = [(head, layername(lm.model, layer)) for (head, layer) in heads_to_noise]\n",
    "head_dim = lm.model.config.n_embd // lm.model.config.n_head\n",
    "def patch_rep(x, layer): # x is the output of the attn forward method (layer), layer is layer num\n",
    "    ## x is tuple (attn_weights, present[key value tracker for MQA], opt(attn_weights))\n",
    "    if layer in [layer for (_, layer) in heads_to_noise]:\n",
    "        for head in [head for (head, layer_) in heads_to_noise if layer_ == layer]:\n",
    "            print(\"patching (layer, head): \", layer, head)\n",
    "            ## noise at the corresponding heads\n",
    "            start = head_dim * head\n",
    "            end = start + head_dim\n",
    "            noise_data = noise_fn(\n",
    "                    torch.from_numpy(prng(x[0].shape[0], x[0].shape[1], head_dim))\n",
    "                ).to(x[0].device)\n",
    "            if replace:\n",
    "                x[0][:,:,start:end] = noise_data\n",
    "            else:\n",
    "                x[0][:,:,start:end] += noise_data\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TraceDict(lm.model, [layername(lm.model, i) for i in range(1, 40)], edit_output_attn=patch_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../results/lookup_table_false_task2.csv\", \"r\") as f:\n",
    "    df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  ['d']0dl\n",
      "True  ['d']1dj\n",
      "True  ['d']2dj\n",
      "True  ['d']3dj\n",
      "True  ['d']4dj\n",
      "False  ['e']5de\n",
      "True  ['d']6dj\n",
      "True  ['d']7dj\n",
      "True  ['d']8dj\n",
      "True  ['k']9kh\n",
      "True  ['k']10kh\n",
      "True  ['k']11kh\n",
      "True  ['k']12kh\n",
      "True  ['k']13kh\n",
      "False  ['j']14kj\n",
      "False  ['j']15kj\n",
      "True  ['k']16kj\n",
      "False  ['j']17kj\n",
      "False  ['j']18kj\n",
      "True  ['k']19kj\n",
      "False  ['j']20kj\n",
      "False  ['j']21kj\n",
      "False  ['a']22ba\n",
      "False  ['a']23ba\n",
      "False  ['a']24bl\n",
      "False  ['a']25ba\n",
      "True  ['b']26bl\n",
      "False  ['a']27bl\n",
      "False  ['a']28bl\n",
      "False  ['a']29bi\n",
      "True  ['b']30bi\n",
      "True  ['b']31bl\n",
      "True  ['b']32bi\n",
      "False  ['i']33bi\n",
      "False  ['a']34bi\n",
      "False  ['a']35bi\n",
      "False  ['a']36ga\n",
      "False  ['e']37ge\n",
      "False  ['e']38ge\n",
      "False  ['a']39gl\n",
      "False  ['a']40gl\n",
      "False  ['l']41gl\n",
      "False  ['e']42gl\n",
      "False  ['e']43gl\n",
      "False  ['a']44gl\n",
      "False  ['a']45ga\n",
      "True  ['k']46km\n",
      "False  ['m']47km\n",
      "False  ['m']48km\n",
      "False  ['m']49km\n",
      "False  ['m']50km\n",
      "False  ['d']51kd\n",
      "False  ['d']52kd\n",
      "False  ['d']53kd\n",
      "False  ['d']54kd\n",
      "False  ['d']55ki\n",
      "True  ['k']56ki\n",
      "False  ['d']57ki\n",
      "True  ['k']58ki\n",
      "False  ['e']59ki\n",
      "True  ['k']60ki\n",
      "False  ['d']61ki\n",
      "False  ['d']62ki\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index, row in df.iterrows():\n",
    "    txt = noise_attn_heads(lm, \n",
    "                        make_lookup_table(12, seed=int(row[\"prompt_seed\"])) + \"\\n\" + make_assert(int(row[\"input n\"])), \n",
    "                        heads_to_noise=[(h, 18) for h in range(48)]+[(h, 17) for h in range(48)])\n",
    "    if txt[0] == row[\"gold\"]:\n",
    "        print(\"True \", str(txt)+str(index)+str(row[\"gold\"])+str(row[\"completion\"]))\n",
    "    else:\n",
    "        print(\"False \", str(txt)+str(index)+str(row[\"gold\"])+str(row[\"completion\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate(make_lookup_table(12, seed=0) + \"\\n\" + make_assert(48),max_new_tokens=1, return_only_generated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt, ret = lm.trace_generate(make_lookup_table(12, seed=0) + \"\\n\" + make_assert(48),\n",
    "                  max_new_toks=1, \n",
    "                  do_greedy_decoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def func(i : int) -> str:\\n    if i == 6:\\n        return \"e\"\\n    elif i == 11:\\n        return \"c\"\\n    elif i == 0:\\n        return \"b\"\\n    elif i == 4:\\n        return \"j\"\\n    elif i == 7:\\n        return \"m\"\\n    elif i == 3:\\n        return \"l\"\\n    elif i == 2:\\n        return \"h\"\\n    elif i == 10:\\n        return \"a\"\\n    elif i == 5:\\n        return \"f\"\\n    elif i == 8:\\n        return \"g\"\\n    elif i == 9:\\n        return \"k\"\\n    elif i == 1:\\n        return \"i\"\\n    else:\\n        return \"d\"\\nassert func(48) == \"j'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def func(i : int) -> str:\n",
      "    if i == 6:\n",
      "        return \"e\"\n",
      "    elif i == 11:\n",
      "        return \"c\"\n",
      "    elif i == 0:\n",
      "        return \"b\"\n",
      "    elif i == 4:\n",
      "        return \"j\"\n",
      "    elif i == 7:\n",
      "        return \"m\"\n",
      "    elif i == 3:\n",
      "        return \"l\"\n",
      "    elif i == 2:\n",
      "        return \"h\"\n",
      "    elif i == 10:\n",
      "        return \"a\"\n",
      "    elif i == 5:\n",
      "        return \"f\"\n",
      "    elif i == 8:\n",
      "        return \"g\"\n",
      "    elif i == 9:\n",
      "        return \"k\"\n",
      "    elif i == 1:\n",
      "        return \"i\"\n",
      "    else:\n",
      "        return \"d\"\n"
     ]
    }
   ],
   "source": [
    "print(make_lookup_table(12, seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechinterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
