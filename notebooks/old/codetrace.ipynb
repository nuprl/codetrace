{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty_d_hKTWPzv"
   },
   "source": [
    "## Causal Tracing\n",
    "\n",
    "Preliminary experiemnts to determine type system knowledge in Code LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-9MF-qu4WPzv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "!echo $CUDA_VISIBLE_DEVICES\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xi_BRR2SWPzw",
    "outputId": "68f2370c-9cd9-4ac7-cda5-e889451eea14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f152d59e5f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, json\n",
    "import torch, numpy\n",
    "from collections import defaultdict\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"~\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../myrome\")\n",
    "\n",
    "from model_utils import *\n",
    "# CACHE_DIR = \"/scratch/lucchetti.f/models/\"\n",
    "# os.environ['TRANSFORMERS_CACHE'] = CACHE_DIR\n",
    "\n",
    "import sys\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "from myrome.experiments.causal_trace import (\n",
    "    ModelAndTokenizer,\n",
    "    layername,\n",
    "    guess_subject,\n",
    "    plot_trace_heatmap\n",
    ")\n",
    "from myrome.experiments.causal_trace import (\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_token,\n",
    "    predict_from_input,\n",
    "    collect_embedding_std,\n",
    "    trace_with_patch,\n",
    "    trace_important_states,\n",
    "    calculate_hidden_flow\n",
    ")\n",
    "from myrome.dsets import KnownsDataset\n",
    "from myrome.util.generate import generate_fast, generate_interactive\n",
    "from model_utils import print_by_line\n",
    "\n",
    "## check has GPTBigCodeConfig\n",
    "from transformers import GPTBigCodeConfig\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:26<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight torch.Size([49152, 6144]) cuda:0\n",
      "transformer.wpe.weight torch.Size([8192, 6144]) cuda:0\n",
      "transformer.h.0.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.0.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.0.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.0.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.0.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.0.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.0.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.0.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.0.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.0.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.0.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.0.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.1.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.1.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.1.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.1.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.1.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.1.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.1.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.1.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.1.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.1.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.1.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.1.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.2.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.2.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.2.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.2.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.2.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.2.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.2.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.2.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.2.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.2.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.2.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.2.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.3.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.3.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.3.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.3.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.3.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.3.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.3.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.3.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.3.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.3.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.3.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.3.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.4.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.4.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.4.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.4.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.4.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.4.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.4.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.4.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.4.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.4.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.4.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.4.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.5.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.5.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.5.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.5.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.5.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.5.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.5.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.5.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.5.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.5.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.5.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.5.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.6.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.6.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.6.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.6.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.6.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.6.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.6.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.6.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.6.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.6.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.6.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.6.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.7.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.7.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.7.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.7.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.7.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.7.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.7.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.7.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.7.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.7.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.7.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.7.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.8.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.8.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.8.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.8.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.8.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.8.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.8.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.8.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.8.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.8.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.8.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.8.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.9.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.9.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.9.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.9.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.9.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.9.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.9.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.9.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.9.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.9.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.9.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.9.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.10.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.10.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.10.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.10.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.10.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.10.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.10.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.10.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.10.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.10.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.10.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.10.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.11.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.11.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.11.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.11.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.11.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.11.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.11.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.11.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.11.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.11.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.11.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.11.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.12.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.12.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.12.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.12.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.12.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.12.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.12.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.12.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.12.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.12.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.12.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.12.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.13.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.13.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.13.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.13.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.13.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.13.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.13.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.13.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.13.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.13.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.13.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.13.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.14.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.14.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.14.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.14.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.14.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.14.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.14.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.14.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.14.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.14.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.14.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.14.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.15.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.15.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.15.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.15.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.15.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.15.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.15.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.15.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.15.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.15.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.15.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.15.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.16.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.16.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.16.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.16.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.16.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.16.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.16.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.16.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.16.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.16.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.16.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.16.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.17.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.17.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.17.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.17.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.17.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.17.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.17.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.17.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.17.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.17.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.17.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.17.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.18.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.18.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.18.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.18.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.18.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.18.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.18.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.18.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.18.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.18.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.18.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.18.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.19.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.19.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.19.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.19.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.19.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.19.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.19.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.19.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.19.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.19.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.19.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.19.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.20.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.20.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.20.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.20.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.20.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.20.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.20.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.20.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.20.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.20.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.20.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.20.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.21.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.21.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.21.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.21.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.21.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.21.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.21.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.21.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.21.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.21.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.21.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.21.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.22.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.22.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.22.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.22.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.22.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.22.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.22.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.22.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.22.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.22.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.22.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.22.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.23.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.23.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.23.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.23.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.23.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.23.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.23.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.23.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.23.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.23.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.23.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.23.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.24.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.24.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.24.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.24.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.24.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.24.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.24.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.24.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.24.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.24.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.24.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.24.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.25.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.25.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.25.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.25.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.25.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.25.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.25.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.25.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.25.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.25.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.25.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.25.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.26.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.26.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.26.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.26.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.26.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.26.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.26.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.26.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.26.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.26.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.26.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.26.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.27.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.27.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.27.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.27.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.27.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.27.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.27.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.27.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.27.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.27.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.27.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.27.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.28.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.28.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.28.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.28.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.28.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.28.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.28.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.28.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.28.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.28.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.28.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.28.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.29.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.29.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.29.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.29.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.29.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.29.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.29.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.29.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.29.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.29.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.29.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.29.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.30.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.30.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.30.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.30.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.30.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.30.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.30.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.30.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.30.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.30.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.30.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.30.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.31.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.31.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.31.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.31.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.31.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.31.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.31.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.31.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.31.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.31.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.31.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.31.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.32.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.32.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.32.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.32.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.32.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.32.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.32.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.32.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.32.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.32.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.32.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.32.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.33.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.33.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.33.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.33.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.33.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.33.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.33.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.33.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.33.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.33.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.33.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.33.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.34.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.34.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.34.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.34.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.34.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.34.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.34.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.34.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.34.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.34.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.34.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.34.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.35.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.35.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.35.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.35.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.35.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.35.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.35.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.35.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.35.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.35.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.35.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.35.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.36.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.36.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.36.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.36.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.36.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.36.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.36.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.36.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.36.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.36.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.36.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.36.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.37.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.37.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.37.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.37.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.37.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.37.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.37.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.37.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.37.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.37.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.37.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.37.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.38.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.38.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.38.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.38.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.38.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.38.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.38.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.38.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.38.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.38.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.38.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.38.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.39.ln_1.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.39.ln_1.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.39.attn.c_attn.weight torch.Size([6400, 6144]) cuda:0\n",
      "transformer.h.39.attn.c_attn.bias torch.Size([6400]) cuda:0\n",
      "transformer.h.39.attn.c_proj.weight torch.Size([6144, 6144]) cuda:0\n",
      "transformer.h.39.attn.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.39.ln_2.weight torch.Size([6144]) cuda:0\n",
      "transformer.h.39.ln_2.bias torch.Size([6144]) cuda:0\n",
      "transformer.h.39.mlp.c_fc.weight torch.Size([24576, 6144]) cuda:0\n",
      "transformer.h.39.mlp.c_fc.bias torch.Size([24576]) cuda:0\n",
      "transformer.h.39.mlp.c_proj.weight torch.Size([6144, 24576]) cuda:0\n",
      "transformer.h.39.mlp.c_proj.bias torch.Size([6144]) cuda:0\n",
      "transformer.ln_f.weight torch.Size([6144]) cuda:0\n",
      "transformer.ln_f.bias torch.Size([6144]) cuda:0\n"
     ]
    }
   ],
   "source": [
    "from trace_model import ModelLoader\n",
    "from pathlib import Path\n",
    "\n",
    "model_name= \"bigcode/starcoder\"\n",
    "# model_name= \"bigcode/santacoder\"\n",
    "# model_path = \"../../microstarcoder\"\n",
    "\n",
    "tm = ModelLoader(model_name, is_remote=False, quiet=False)\n",
    "\n",
    "model=tm.model\n",
    "tokenizer=tm.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62136934400 / 84979089408 used for device 0, reserved 62138613760\n"
     ]
    }
   ],
   "source": [
    "check_devs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Examining traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "- grab layers that give correct output in trace\n",
    "- measure k value (Rank) of correct output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franlucc/codetrace/notebooks/../trace_model.py:150: UserWarning: The model `bigcode/starcoder` of type `gpt_bigcode` already implements or can't utilize `use_cache` for fast generation. Setting `use_cache = False`.\n",
      "  warnings.warn(f\"The model `{self.model_name}` of type `{self.model_type}` already implements or can't utilize `use_cache` for fast generation. Setting `use_cache = False`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt <0> ==> [(' ', 0.6333), (' -', 0.0318), (' (', 0.0177), (' x', 0.0172), (' %', 0.0146)]\n",
      "prompt <0> ==> [('0', 0.7563), ('1', 0.1451), ('2', 0.0336), ('3', 0.0192), ('5', 0.0137)]\n",
      "prompt <0> ==> [(';', 0.9095), (',', 0.0309), (';\\\\', 0.0153), (' ;', 0.0116), ('\\n', 0.0028)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['int x = 0;'],\n",
       " {'input_tokenized': [[('int', 410), (' x', 816), (' =', 280)]],\n",
       "  'generated_tokens': [[[{'token': ' ', 'id': 225, 'p': 0.6333003044128418},\n",
       "     {'token': ' -', 'id': 429, 'p': 0.03179261460900307},\n",
       "     {'token': ' (', 'id': 308, 'p': 0.017688540741801262},\n",
       "     {'token': ' x', 'id': 816, 'p': 0.017215397208929062},\n",
       "     {'token': ' %', 'id': 904, 'p': 0.014598190784454346}],\n",
       "    [{'token': '0', 'id': 34, 'p': 0.7562679052352905},\n",
       "     {'token': '1', 'id': 35, 'p': 0.1451088786125183},\n",
       "     {'token': '2', 'id': 36, 'p': 0.033597081899642944},\n",
       "     {'token': '3', 'id': 37, 'p': 0.019215252250432968},\n",
       "     {'token': '5', 'id': 39, 'p': 0.013744757510721684}],\n",
       "    [{'token': ';', 'id': 45, 'p': 0.9095149040222168},\n",
       "     {'token': ',', 'id': 30, 'p': 0.03092985786497593},\n",
       "     {'token': ';\\\\', 'id': 8871, 'p': 0.015337608754634857},\n",
       "     {'token': ' ;', 'id': 2082, 'p': 0.011616121046245098},\n",
       "     {'token': '\\n', 'id': 203, 'p': 0.002759486436843872}]]],\n",
       "  'activations': {'transformer.h.2': array([[[ 3.1692789 , -0.3021816 , -0.9571408 , ..., -1.0756444 ,\n",
       "             1.2447085 , -0.39584547],\n",
       "           [ 1.2627158 , -0.05459108, -1.4308141 , ..., -1.7405174 ,\n",
       "             0.24269965, -1.5555146 ],\n",
       "           [ 1.1286145 ,  0.19219325,  0.09476294, ..., -0.03772134,\n",
       "            -0.1314193 ,  0.32077783],\n",
       "           [ 1.4409667 ,  0.19988114,  0.21179764, ..., -0.03052011,\n",
       "             0.08333994,  0.00481369],\n",
       "           [ 1.3992794 ,  0.19427034,  0.18169755, ..., -0.07360364,\n",
       "            -0.34807315,  0.11705329]]], dtype=float32)}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [\"int x =\"]\n",
    "\n",
    "n = 4 # num transformer blocks\n",
    "txt, ret_dict = tm.sample_generate(\n",
    "    prompts,\n",
    "    max_out_len=6,\n",
    "    argmax_greedy= True,\n",
    "    debug = True,\n",
    "    \n",
    "    request_activations= [tm.layer_name_format.format(i) for i in range(2,3)],\n",
    ")\n",
    "txt, ret_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTBigCodeForCausalLM(\n",
      "  (transformer): GPTBigCodeModel(\n",
      "    (wte): Embedding(49152, 6144)\n",
      "    (wpe): Embedding(8192, 6144)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-39): 40 x GPTBigCodeBlock(\n",
      "        (ln_1): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPTBigCodeAttention(\n",
      "          (c_attn): Linear(in_features=6144, out_features=6400, bias=True)\n",
      "          (c_proj): Linear(in_features=6144, out_features=6144, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPTBigCodeMLP(\n",
      "          (c_fc): Linear(in_features=6144, out_features=24576, bias=True)\n",
      "          (c_proj): Linear(in_features=24576, out_features=6144, bias=True)\n",
      "          (act): GELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=6144, out_features=49152, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "prompt = \"static int func(){\\nint x = 0;\\nint y = 1;\\nint z =\"\n",
    "text = generate_interactive(model, tokenizer, use_logit_lens=True, top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4611912704 / 34079899648 used for device 0, reserved 4632608768\n"
     ]
    }
   ],
   "source": [
    "check_devs()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mechinterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
