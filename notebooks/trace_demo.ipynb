{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax-dependent trace\n",
    "\n",
    "Head attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franlucc/mechinterp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 84979089408 used for device 0, reserved 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## discovery cluster setup\n",
    "# CACHE_DIR = \"/scratch/lucchetti.f/models/\"\n",
    "# os.environ['TRANSFORMERS_CACHE'] = CACHE_DIR\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "from model_utils import *\n",
    "import tqdm as notebook_tqdm\n",
    "from trace_model import ModelLoader\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "#MODEL_NAME = \"Salesforce/codegen-16B-mono\"\n",
    "MODEL_NAME = \"bigcode/starcoder\"\n",
    "\n",
    "check_devs()\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:27<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62136934400 / 84979089408 used for device 0, reserved 62138613760\n"
     ]
    }
   ],
   "source": [
    "lm = ModelLoader(MODEL_NAME)\n",
    "check_devs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "def add_multiply(n):\n",
      "    \"\"\"\n",
      "    Takes a number n and in order adds the digits and then multiplies the digits. For example, \n",
      "    the number 345 would be (3+4)*5.\n",
      "    \"\"\"\n",
      "    s = str(n)\n",
      "    result = int(s[0])\n",
      "    for i in range(1, len(s)):\n",
      "        if i % 2 == 1:\n",
      "            result += int(s[i])\n",
      "        else:\n",
      "            result *= int(s[i])\n",
      "    return result\n",
      "\n",
      "def can_say(s_long, word):\n",
      "    \"\"\"\n",
      "    Checks if the first string contains all the letters of the word in order.\n",
      "    \"\"\"\n",
      "    s_long = s_long.lower()\n",
      "    word = word.lower()\n",
      "    for s in word:\n",
      "        if s_long.find(s) == -1:\n",
      "            return False\n",
      "        s_long = s_long[s_long.index(s) + 1:]\n",
      "    return True\n",
      "    \n",
      "def square_smallest_digit(n):\n",
      "    \"\"\"\n",
      "    Squares the smallest digit in n\n",
      "    \"\"\"\n",
      "    num = str(n)\n",
      "    smallest = 10\n",
      "    for s in num:\n",
      "        smallest = int(s) if int(s) < smallest else smallest\n",
      "    return smallest ** 2\n",
      "\n",
      "def sum_square_difference(n):\n",
      "    \"\"\"\n",
      "    Finds the difference between the sum of the squares of the first n natural numbers and the square of the sum.\n",
      "    \"\"\"\n",
      "    sum_of_squares = 0\n",
      "    square_of_sum = 0\n",
      "    for i in range(1, n + 1):\n",
      "        sum_of_squares += i ** 2\n",
      "        square_of_sum += i\n",
      "    return square_of_sum ** 2 - sum_of_\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\"\"\"\n",
    "def add_multiply(n):\n",
    "    \"\"\"\n",
    "    Takes a number n and in order adds the digits and then multiplies the digits. For example, \n",
    "    the number 345 would be (3+4)*5.\n",
    "    \"\"\"\n",
    "    s = str(n)\n",
    "    result = int(s[0])\n",
    "    for i in range(1, len(s)):\n",
    "        if i % 2 == 1:\n",
    "            result += int(s[i])\n",
    "        else:\n",
    "            result *= int(s[i])\n",
    "    return result\n",
    "\n",
    "def can_say(s_long, word):\n",
    "    \"\"\"\n",
    "    Checks if the first string contains all the letters of the word in order.\n",
    "    \"\"\"\n",
    "    s_long = s_long.lower()\n",
    "    word = word.lower()\n",
    "    for s in word:\n",
    "        if s_long.find(s) == -1:\n",
    "            return False\n",
    "        s_long = s_long[s_long.index(s) + 1:]\n",
    "    return True\n",
    "    \n",
    "def square_smallest_digit(n):\n",
    "    \"\"\"\n",
    "    Squares the smallest digit in n\n",
    "    \"\"\"\n",
    "    num = str(n)\n",
    "    smallest = 10\n",
    "    for s in num:\n",
    "        smallest = int(s) if int(s) < smallest else smallest\n",
    "    return smallest ** 2\n",
    "\n",
    "def'''\n",
    "\n",
    "toks = lm.tokenizer([prompt], padding=True, return_tensors='pt').to(lm.model.device)\n",
    "out = lm.model.generate(**toks, max_new_tokens=100)\n",
    "x = lm.tokenizer.decode(out.squeeze().tolist())\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franlucc/codetrace/notebooks/../trace_model.py:129: UserWarning: The model `bigcode/starcoder` of type `gpt_bigcode` already implements or can't utilize `use_cache` for fast generation. Setting `use_cache = False`.\n",
      "  warnings.warn(f\"The model `{self.model_name}` of type `{self.model_type}` already implements or can't utilize `use_cache` for fast generation. Setting `use_cache = False`.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt <0> ==> [('0', 0.98), ('1', 0.0199), ('2', 0.0001), ('3', 0.0), ('4', 0.0), ('5', 0.0), ('9', 0.0), ('6', 0.0), ('8', 0.0), ('7', 0.0), (' ', 0.0), (' (', 0.0), ('<fim_middle>', 0.0), (' first', 0.0), ('<fim_suffix>', 0.0), (' i', 0.0), (' range', 0.0), (' -', 0.0), ('<fim_pad>', 0.0), ('ith', 0.0)]\n",
      "prompt <0> ==> [(';', 0.9777), (',', 0.0127), (' ;', 0.0094), (' ', 0.0), (' ,', 0.0), (' i', 0.0), (';(', 0.0), (' +', 0.0), (' /*', 0.0), (' to', 0.0), (' (', 0.0), (';;', 0.0), (' <', 0.0), ('.', 0.0), ('/*', 0.0), ('(', 0.0), ('L', 0.0), ('  ', 0.0), (' :', 0.0), (' -', 0.0)]\n",
      "prompt <0> ==> [(' i', 0.9921), (' (', 0.0047), ('i', 0.0018), (' ', 0.0011), (' ((', 0.0001), (' numbers', 0.0001), (' true', 0.0), ('\\n            ', 0.0), (' ;', 0.0), (' ++', 0.0), ('\\n           ', 0.0), ('\\n               ', 0.0), ('  ', 0.0), (' number', 0.0), (' Math', 0.0), (' /*', 0.0), ('   ', 0.0), (' Integer', 0.0), (' Numbers', 0.0), (' Float', 0.0)]\n",
      "prompt <0> ==> [(' <', 0.9738), (' <=', 0.0095), (' +', 0.0073), ('<', 0.0051), (' !=', 0.0025), ('+', 0.0008), ('<(', 0.0005), (' ', 0.0002), (' >', 0.0001), (' >=', 0.0001), ('<=', 0.0), (' -', 0.0), (' ==', 0.0), (' &', 0.0), ('!=', 0.0), (' *', 0.0), (' (', 0.0), ('+(', 0.0), ('(', 0.0), ('-', 0.0)]\n",
      "prompt <0> ==> [(' numbers', 0.8657), (' (', 0.132), (' ((', 0.0005), ('numbers', 0.0003), (' ', 0.0002), ('(', 0.0002), (' number', 0.0001), (' Math', 0.0001), (' num', 0.0001), (' len', 0.0001), (' Numbers', 0.0001), (' n', 0.0001), (' nums', 0.0001), (' size', 0.0), (' numberOf', 0.0), (' length', 0.0), (' NUMBER', 0.0), (' Number', 0.0), (' list', 0.0), (' Integer', 0.0)]\n",
      "prompt <0> ==> [('.', 0.9999), (' .', 0.0001), ('\\n           ', 0.0), ('\\n               ', 0.0), ('.<', 0.0), (' -', 0.0), ('().', 0.0), (';', 0.0), ('\\n       ', 0.0), ('(', 0.0), ('Size', 0.0), ('_', 0.0), ('\\n         ', 0.0), ('\\n             ', 0.0), ('.__', 0.0), (',', 0.0), ('\\n              ', 0.0), ('\\n            ', 0.0), ('-', 0.0), ('._', 0.0)]\n",
      "prompt <0> ==> [('size', 0.9998), ('lastIndexOf', 0.0), ('length', 0.0), ('sub', 0.0), ('indexOf', 0.0), (' size', 0.0), ('si', 0.0), ('stream', 0.0), ('toArray', 0.0), ('get', 0.0), ('isEmpty', 0.0), ('Size', 0.0), ('list', 0.0), ('s', 0.0), ('last', 0.0), ('getSize', 0.0), ('capacity', 0.0), ('SIZE', 0.0), ('count', 0.0), ('getLast', 0.0)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">23</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">for (int i = \"\"\"</span>]                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>23 txt, ret_dict = lm.trace_generate(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>prompts,                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>max_out_len=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(prompts[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]) + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>argmax_greedy= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/franlucc/codetrace/notebooks/../</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trace_model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">177</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trace_generate</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>softmax_out_top_k = softmax_out_top_k / softmax_out_top_k.sum(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)[:, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">176 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span>(argmax_greedy == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>177 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>new_tok_indices = torch.multinomial(softmax_out_top_k, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>new_toks = torch.gather(tk, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, new_tok_indices)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m23\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mfor (int i = \u001b[0m\u001b[33m\"\"\"\u001b[0m]                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m23 txt, ret_dict = lm.trace_generate(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m24 \u001b[0m\u001b[2m│   \u001b[0mprompts,                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2m│   \u001b[0mmax_out_len=\u001b[96mlen\u001b[0m(prompts[\u001b[94m0\u001b[0m]) + \u001b[94m10\u001b[0m,                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m│   \u001b[0margmax_greedy= \u001b[94mFalse\u001b[0m,                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/franlucc/codetrace/notebooks/../\u001b[0m\u001b[1;33mtrace_model.py\u001b[0m:\u001b[94m177\u001b[0m in \u001b[92mtrace_generate\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msoftmax_out_top_k = softmax_out_top_k / softmax_out_top_k.sum(\u001b[94m1\u001b[0m)[:, \u001b[94mNone\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m175 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m176 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m(argmax_greedy == \u001b[94mFalse\u001b[0m):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m177 \u001b[2m│   │   │   │   │   \u001b[0mnew_tok_indices = torch.multinomial(softmax_out_top_k, \u001b[94m1\u001b[0m)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mnew_toks = torch.gather(tk, \u001b[94m1\u001b[0m, new_tok_indices)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m179 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m180 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = [\"\"\"import java.util.*;\n",
    "import java.lang.reflect.*;\n",
    "import org.javatuples.*;\n",
    "import java.security.*;\n",
    "import java.math.*;\n",
    "import java.io.*;\n",
    "import java.util.stream.*;\n",
    "class Problem {\n",
    "    // Check if in given array list of numbers, are any two numbers closer to each other than\n",
    "    // given threshold.\n",
    "    // >>> hasCloseElements((new ArrayList<Float>(Arrays.asList((float)1.0f, (float)2.0f, (float)3.0f))), (0.5f))\n",
    "    // (false)\n",
    "    // >>> hasCloseElements((new ArrayList<Float>(Arrays.asList((float)1.0f, (float)2.8f, (float)3.0f, (float)4.0f, (float)5.0f, (float)2.0f))), (0.3f))\n",
    "    // (true)\n",
    "    public static boolean hasCloseElements(ArrayList<Float> numbers, float threshold) {\n",
    "        // Sort the list in ascending order\n",
    "        Collections.sort(numbers);\n",
    "        // Iterate from the first to one less than last index, and check each element with the element\n",
    "        // immediately to its right.\n",
    "        for (int i = \"\"\"]\n",
    "\n",
    "\n",
    "txt, ret_dict = lm.trace_generate(\n",
    "    prompts,\n",
    "    max_out_len=len(prompts[0]) + 10,\n",
    "    argmax_greedy= False,\n",
    "    debug = True,\n",
    "    request_activations= [lm.layer_name_format.format(i) for i in range(0,lm.model.config.n_layer)],\n",
    "    use_cache=False,\n",
    "    top_k = 20,\n",
    ")\n",
    "txt, ret_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Argument Model Logit Lens ---\n",
      "0: [(' ', 1), ('<fim_suffix>', 0), ('\\n', 0), ('1', 0), (' (', 0)]\n",
      "1: [(' ', 0), ('<fim_suffix>', 0), ('1', 0), ('\\n', 0), (' (', 0)]\n",
      "2: [('<fim_suffix>', 0), (' ', 0), ('1', 0), (' (', 0), ('0', 0)]\n",
      "3: [('<fim_suffix>', 1), ('1', 0), (' ', 0), ('0', 0), (' (', 0)]\n",
      "4: [('<fim_suffix>', 1), ('1', 1), ('0', 1), (' ', 0), (' (', 0)]\n",
      "5: [('0', 2), ('1', 1), ('<fim_suffix>', 1), (' ', 1), (' (', 0)]\n",
      "6: [('0', 3), ('1', 2), (' ', 1), ('<fim_suffix>', 1), (' (', 1)]\n",
      "7: [('0', 6), ('1', 3), (' ', 2), (' (', 1), ('2', 1)]\n",
      "8: [('0', 9), ('1', 4), (' ', 2), ('2', 1), ('<fim_suffix>', 1)]\n",
      "9: [('0', 12), ('1', 6), (' ', 2), ('2', 1), ('<fim_suffix>', 1)]\n",
      "10: [('0', 22), ('1', 10), (' ', 2), ('2', 1), ('i', 1)]\n",
      "11: [('0', 29), ('1', 11), (' ', 3), ('i', 2), ('<fim_suffix>', 2)]\n",
      "12: [('0', 34), ('1', 14), ('i', 2), ('2', 1), (' ', 1)]\n",
      "13: [('0', 34), ('1', 10), ('i', 1), ('2', 1), ('I', 1)]\n",
      "14: [('0', 23), ('1', 4), ('i', 2), ('my', 1), ('<fim_suffix>', 1)]\n",
      "15: [('0', 32), ('1', 7), ('i', 2), ('my', 1), ('<fim_suffix>', 1)]\n",
      "16: [('0', 43), ('1', 11), ('2', 2), ('i', 2), ('<fim_suffix>', 2)]\n",
      "17: [('0', 53), ('1', 6), ('<fim_suffix>', 2), ('i', 1), ('2', 1)]\n",
      "18: [('0', 49), ('1', 8), ('2', 1), ('<fim_suffix>', 1), ('i', 1)]\n",
      "19: [('0', 41), ('1', 5), ('2', 1), ('lite', 0), ('3', 0)]\n",
      "20: [('0', 69), ('1', 4), ('2', 1), ('<fim_suffix>', 0), ('i', 0)]\n",
      "21: [('0', 75), ('1', 6), ('lil', 1), ('i', 0), ('2', 0)]\n",
      "22: [('0', 83), ('1', 12), ('lil', 0), ('2', 0), ('i', 0)]\n",
      "23: [('0', 91), ('1', 6), ('<fim_suffix>', 0), ('lil', 0), ('2', 0)]\n",
      "24: [('0', 94), ('1', 4), ('<fim_suffix>', 0), ('len', 0), ('2', 0)]\n",
      "25: [('0', 92), ('1', 6), ('2', 0), (' (', 0), (' pairs', 0)]\n",
      "26: [('0', 92), ('1', 6), ('first', 0), (' first', 0), (' (', 0)]\n",
      "27: [('0', 88), ('1', 10), ('first', 0), (' first', 0), (' (', 0)]\n",
      "28: [('0', 96), ('1', 4), (' ', 0), (' first', 0), ('first', 0)]\n",
      "29: [('0', 97), ('1', 3), (' ', 0), (' (', 0), (' first', 0)]\n",
      "30: [('0', 98), ('1', 2), (' ', 0), (' first', 0), (' (', 0)]\n",
      "31: [('0', 99), ('1', 1), (' ', 0), (' (', 0), (' first', 0)]\n",
      "32: [('0', 99), ('1', 1), (' first', 0), ('first', 0), (' (', 0)]\n",
      "33: [('0', 99), ('1', 1), (' first', 0), (' (', 0), ('first', 0)]\n",
      "34: [('0', 99), ('1', 1), (' first', 0), ('2', 0), ('first', 0)]\n",
      "35: [('0', 100), ('1', 0), ('2', 0), (' first', 0), (' (', 0)]\n",
      "36: [('0', 100), ('1', 0), ('2', 0), ('3', 0), (' first', 0)]\n",
      "37: [('0', 100), ('1', 0), ('2', 0), ('3', 0), ('4', 0)]\n",
      "38: [('0', 100), ('1', 0), ('2', 0), ('3', 0), ('4', 0)]\n",
      "39: [('0', 98), ('1', 2), ('2', 0), ('3', 0), ('4', 0)]\n"
     ]
    }
   ],
   "source": [
    "lm.get_logits(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechinterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
